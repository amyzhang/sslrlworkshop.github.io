---
layout: project
urltitle:  "Self-supervision for reinforcement learning (SSL-RL)"
title: "Self-supervision for reinforcement learning (SSL-RL)"
categories: workshop, iclr, self-supervised learning, reinforcement learning, deep learning, 2021
permalink: /
bibtex: true
paper: true
acknowledgements: ""
---

<br>
<div class="row">
  <div class="col-xs-12">
    <center><h1>Self-supervision for reinforcement learning (SSL-RL)</h1></center>
    <center><h2>May 8, 2021. ICLR Workshop.</h2></center>
  </div>
</div>

<br />

<div class="row">
    <div class="col-xs-12">
        <p>
          Reinforcement learning (RL) entails letting an agent learn through interaction with an environment. The formalism is powerful in it’s generality, and presents us with a hard open-ended problem: how can we design agents that learn efficiently, and generalize well, given only sensory information and a scalar reward signal? The goal of this workshop is to explore the role of self-supervised learning within reinforcement learning agents, to make progress towards this goal. 
        </p>
    </div>
</div>


<br />

<div class="row" id="dates">
  <div class="col-xs-12">
    <h2>Important Dates</h2>
  </div>
</div>

<br>
<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>Paper Submission Deadline</td>
          <td>February 22, 2021 AoE</td>
        </tr>
        <tr>
          <td>Decision Notifications</td>
          <td>March 26, 2021 </td>
        </tr>
        <tr>
          <td>Camera Ready Paper Deadline</td>
          <td>April 15, 2021 AoE</td>
        </tr>
        <tr>
          <td>Workshop</td>
          <td>May 8, 2021</td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<br />

<div class="row" id="cfp">
  <div class="col-xs-12">
    <h2>Call for Papers</h2>
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <p>
      The authors are welcome to submit a 4-page paper based on in-progress work, or relevant paper being presented at the main conference, on any of the following topics:
    </p>
    <p>
          <ul>
  <li>How can we leverage unsupervised data to bootstrap learning in an MDP, and what primitives should we learn: dynamics, representation, skills or something else?</li>
              <li>How can we measure progress in development of self-supervised, general purpose agents? Do we need to create a GLUE like benchmark for RL?</li>
            <li>What kind of structure in an MDP can an agent exploit to learn a task faster?</li>
            <li>How can we design self-supervised objectives that encourage an agent to generalize well out of its training distribution?</li>
            <li>Can we leverage insights from cognitive science on how humans acquire knowledge to build better self-supervised objectives?</li>
          </ul>
      </p>
      <p>We welcome review and positional papers that may foster discussions. We also encourage published papers from <i>*non-ML*</i> conferences, e.g. epistemology, cognitive science, psychology, neuroscience, that are within the scope of the workshop. </p>
  </div>
</div>


<br />

<div class="row" id="guidelines">
  <div class="col-xs-12">
    <h2>Submission Guidelines</h2>
  </div>
</div>

<div class="row">
    <div class="col-xs-12">
      <p>
            Please upload submissions at: <b><a href="https://openreview.net/group?id=ICLR.cc/2021/Workshop/SSL-RL" style="color:black">SSL-RL submission website</a></b>
        </p>
    <ul>
      <li><b>Previously published work</b>: We welcome previously published papers from non-ML conferences, will also accept cross-submissions from ML conferences (including ICLR 2021) which are within the scope of the workshop without re-formatting. These specific papers do not have to be anonymous. They are eligible for poster sessions and will only have a very light review process.</li>
      <li><b>Unpublished work</b>: All submissions must be in PDF format. The submissions must be formated using the ICLR 2021 LaTeX style file. Submissions are limited to 8 content pages, including all figures and tables; additional pages containing statements of acknowledgements and funding disclosures, and references are allowed. The maximum file size for submissions is 50MB. The CMT-based review process will be double-blind to avoid potential conflicts of interests.</li>
    </ul>
    <p>
            In case of any issues, feel free to email the workshop organizers at: <b>sslrl.ws.iclr2021@gmail.com</b>
    </p>
    </div>
</div>


<hr />

<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2>Speakers</h2>
  </div>
</div>

<div class="row">
  <div class="col-xs-6 col-lg-3">
    <a href="http://www.pyoudeyer.com/">
      <img class="people-pic" src="{{ "/static/img/people/py_oudeyer.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="http://www.pyoudeyer.com/">Pierre-Yves Oudeyer</a>
      <h6>INRIA/ Flowers team</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="https://scholar.google.com/citations?user=YWVuCKUAAAAJ&hl=en">
      <img class="people-pic" src="{{ "/static/img/people/irina_higgins.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=YWVuCKUAAAAJ&hl=en">Irina Higgins</a>
      <h6>DeepMind</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="https://danijar.com/">
      <img class="people-pic" src="{{ "/static/img/people/danijar_hafner.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://danijar.com/">Danijar Hafner</a>
      <h6>University of Toronto</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="http://www.elisevanderpol.nl/">
      <img class="people-pic" src="{{ "/static/img/people/elise_van_der_pol.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="http://www.elisevanderpol.nl/">Elise van der Pol</a>
      <h6>University of Amsterdam</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="https://www.microsoft.com/en-us/research/people/jcl/">
      <img class="people-pic" src="{{ "/static/img/people/john_langford.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.microsoft.com/en-us/research/people/jcl/">John Langford</a>
      <h6>Microsoft Research, New York</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="http://www.princeton.edu/~yael/">
      <img class="people-pic" src="{{ "/static/img/people/yael_niv.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="http://www.princeton.edu/~yael/">Yael Niv</a>
      <h6>Princeton</h6>
    </div>
  </div>
</div>

<hr />

<div class="row" id="intro">
    <div class="col-xs-12">
        <h2>Introduction</h2>
        <p>Self-Supervised Learning for a RL agent involves the agent learning (and possibly discovering) many predictions about it’s world. For example, a natural self-supervised prediction task within an agent is to learn the transition dynamics of the environment [1-4]. But given the rich sequential and interactive nature of RL environments, many other prediction tasks could be used as well [5-8]. Self-supervised learning has several possible benefits. First, the agent can directly use its learned primitives to facilitate future learning, by endowing itself with learned priors instead of starting tabula-rasa [9-11]. Second, the agent can indirectly benefit from the learned predictions, by learning a representation that is useful for many different predictions [12]. Such a representation should also facilitate efficient learning [13-14] and exhibit better generalization [15-16]</p>. 

        <p> The aims of this workshop are to explore the potential benefits of self-supervision, how to specify self-supervised tasks, and to bring together people from different areas, including Cognitive Science, Reinforcement Learning, and Computer Vision, with a common interest in building better learning agents. The specific research questions we hope to tackle include:</p>
        <ul>
        <li>How can we leverage unsupervised data to bootstrap learning in an MDP, and what primitives should we learn: dynamics, representation, skills or something else?</li>
        <li>How can we measure progress in development of self-supervised, general purpose agents? Do we need to create a GLUE like benchmark for RL?</li>
        <li>What kind of structure in an MDP can an agent exploit to learn a task faster?</li>
        <li>How can we design self-supervised objectives that encourage an agent to generalize well out of its training distribution?</li>
        <li>Can we leverage insights from cognitive science on how humans acquire knowledge to build better self-supervised objectives?</li>
        </ul>
    </div>
</div>

<hr />

<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-6 col-lg-3">
    <a href="https://amyzhang.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/amy_zhang.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://amyzhang.github.io/">Amy Zhang</a>
      <h6>McGill University / Mila / Facebook</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="https://ankeshanand.com/">
      <img class="people-pic" src="{{ "/static/img/people/ankesh_anand.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://ankeshanand.com/">Ankesh Anand</a>
      <h6>University of Montreal / Mila</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="https://bmazoure.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/bogdan_mazoure.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://bmazoure.github.io/">Bogdan Mazoure</a>
      <h6>McGill University / Mila</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="https://rdevon.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/devon_hjelm.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://rdevon.github.io/">Devon Hjelm</a>
      <h6>Microsoft Research / University of Montreal</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="https://sites.ualberta.ca/~kjaved/">
      <img class="people-pic" src="{{ "/static/img/people/khurram_javed.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://sites.ualberta.ca/~kjaved/">Khurram Javed</a>
      <h6>University of Alberta / AMII</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="http://webdocs.cs.ualberta.ca/~whitem/">
      <img class="people-pic" src="{{ "/static/img/people/martha_white.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="http://webdocs.cs.ualberta.ca/~whitem/">Martha White</a>
      <h6>University of Alberta / AMII</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="https://tldoan.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/thang_doan.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://tldoan.github.io/">Thang Doan</a>
      <h6>McGill University / Mila</h6>
    </div>
  </div>
</div>

<hr />


<div class="row">
  <div class="col-xs-12">
    <h2>References</h2>
  </div>
</div>
<div class="row">
  <div class="col-md-12">
    <ol>
<li>Finn, Chelsea, Ian Goodfellow, and Sergey Levine. "Unsupervised learning for physical interaction through video prediction." <i>Advances in neural information processing systems.</i> (2016).</li>   
<li>Ha, David, and Jürgen Schmidhuber. "Recurrent world models facilitate policy evolution." Advances in Neural Information Processing Systems. (2018). </li>
<li>Hafner, Danijar, et al. "Learning latent dynamics for planning from pixels." International Conference on Machine Learning. PMLR.  (2019).  </li>
<li>Kipf, Thomas, Elise van der Pol, and Max Welling. "Contrastive learning of structured world models." arXiv.  (2019). </li>
<li>Schmidhuber, Jürgen. "A possibility for implementing curiosity and boredom in model-building neural controllers." Proc. of the international conference on simulation of adaptive behavior: From animals to animals.  (1991). </li>
<li>Klyubin, Alexander S., Daniel Polani, and Chrystopher L. Nehaniv. "Empowerment: A universal agent-centric measure of control." IEEE Congress on Evolutionary Computation.  (2005). </li>
<li>Mohamed, Shakir, and Danilo Jimenez Rezende. "Variational information maximisation for intrinsically motivated reinforcement learning." Advances in neural information processing systems.  (2015). </li>
<li>Pathak, Deepak, et al. "Curiosity-driven exploration by self-supervised prediction." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops.  (2017). </li>
<li>Ebert, Frederik, et al. "Visual foresight: Model-based deep reinforcement learning for vision-based robotic control." arXiv.  (2018). </li>
<li>Sekar, Ramanan, et al. "Planning to Explore via Self-Supervised World Models." arXiv.  (2020). </li>
<li>Lynch, Corey, et al. "Learning latent plans from play." Conference on Robot Learning. (2020). </li>
<li>Jaderberg, Max, et al. "Reinforcement learning with unsupervised auxiliary tasks." arXiv.(2016). </li>
<li>Eslami, SM Ali, et al. "Neural scene representation and rendering." Science. (2018). </li>
<li>Schwarzer, Max, et al. "Data-Efficient Reinforcement Learning with Self-Predictive Representations." arXiv.  (2020). </li>
<li>Zhang, Amy, et al. "Learning invariant representations for reinforcement learning without reconstruction." arXiv.  (2020).  </li>
<li>Mazoure, Bogdan, et al. "Deep reinforcement and infomax learning." Advances in Neural Information Processing Systems (2020). </li>
<li>Hansen, Nicklas, et al. "Self-Supervised Policy Adaptation during Deployment." arXiv. (2020). </li>
</ol>
  </div>
</div>

<div class="text-center p-3" style="background-color: rgba(0, 0, 0, 0)">
    <h6>Website theme inspired from <a href="https://github.com/vigilworkshop/vigilworkshop.github.io" class="h6">VIGIL workshop</a></h6>
  </div>
